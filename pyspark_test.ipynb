{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac3ba4f-9413-4d22-9c09-46d05afc9e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import avg, col, when, row_number\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2af03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docker inspect -f '{{range.NetworkSettings.Networks}}{{.IPAddress}}{{end}}' spark_spark_1\n",
    "\n",
    "with open(\"remote_ip.txt\") as f:\n",
    "    scheduler_ip = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f8b44",
   "metadata": {},
   "source": [
    "## GCP\n",
    "Currently uses local pyspark to connect to my existing GCP resources. Intention is to use local containers instead of submitting jobs to dataproc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8868726",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"gcp\")\n",
    "    #.config(\"spark.master\", f\"spark://{scheduler_ip}:7077\")\n",
    "    .config(\"spark.jars\", \"spark-3.3-bigquery-0.32.2.jar,gcs-connector-hadoop3-latest.jar\")\n",
    "    .config(\"spark.master\", \"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
    "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\",\"methodical-aura-373904-585595bbc316.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "016de9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+--------------------+-----------------+---------+\n",
      "|RANK|               NAME|          INDUSTRIES|COUNTRY/TERRITORY|EMPLOYEES|\n",
      "+----+-------------------+--------------------+-----------------+---------+\n",
      "|  1.|Samsung Electronics|Semiconductors, E...|       South Kore|  266,673|\n",
      "|  2.|          Microsoft|IT, Internet, Sof...|    United States|  221,000|\n",
      "|  3.|                IBM|Semiconductors, E...|    United States|  250,000|\n",
      "|  4.|           Alphabet|IT, Internet, Sof...|    United States|  156,500|\n",
      "|  5.|              Apple|Semiconductors, E...|    United States|  154,000|\n",
      "|  6.|    Delta Air Lines|Transportation an...|    United States|   80,000|\n",
      "|  7.|   Costco Wholesale|Retail and Wholesale|    United States|  288,000|\n",
      "|  8.|              Adobe|IT, Internet, Sof...|    United States|   25,988|\n",
      "|  9.| Southwest Airlines|Transportation an...|    United States|   55,093|\n",
      "| 10.|  Dell Technologies|Semiconductors, E...|    United States|  133,000|\n",
      "| 11.|    Lockheed Martin| Aerospace & Defense|    United States|  114,000|\n",
      "| 12.|      Cisco Systems|Semiconductors, E...|    United States|   79,500|\n",
      "| 13.|          BMW Group|Automotive (Autom...|          Germany|  118,909|\n",
      "| 14.|             Amazon|IT, Internet, Sof...|    United States|1,608,000|\n",
      "| 15.|          Decathlon|Retail and Wholesale|           France|  100,000|\n",
      "| 16.|             Adidas|Clothing, Shoes, ...|          Germany|   61,401|\n",
      "| 17.|             AIRBUS| Aerospace & Defense|      Netherlands|  125,000|\n",
      "| 18.|            Ferrari|Automotive (Autom...|            Italy|    4,556|\n",
      "| 19.| Fraunhofer Society| Healthcare & Social|          Germany|   30,028|\n",
      "| 20.|Reliance Industries|        Conglomerate|            India|  230,000|\n",
      "+----+-------------------+--------------------+-----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"gs://mark-dbt-learn-bucket/Worlds_Best_Employers.csv\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea68749",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"dataproc-temp-us-east1-49528533322-xcoaaowy\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0333981b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+-------------+----------------+------------+----------+-----------------+---------------------+--------------+-----------+-----------+-----------------------+------------------+---------------+--------------------+-------------+------------+-------------+-------------+--------------+-----------------+---------------------+--------------+-------------+------------------+------------------------+---------------------------+---------------+---------------+---------+-----------------------+------------------+------------+--------------+-------------+---------+----------+---------+--------------+----+\n",
      "|months_as_customer|age|policy_number|policy_bind_date|policy_state|policy_csl|policy_deductable|policy_annual_premium|umbrella_limit|insured_zip|insured_sex|insured_education_level|insured_occupation|insured_hobbies|insured_relationship|capital_gains|capital_loss|incident_date|incident_type|collision_type|incident_severity|authorities_contacted|incident_state|incident_city| incident_location|incident_hour_of_the_day|number_of_vehicles_involved|property_damage|bodily_injuries|witnesses|police_report_available|total_claim_amount|injury_claim|property_claim|vehicle_claim|auto_make|auto_model|auto_year|fraud_reported|_c39|\n",
      "+------------------+---+-------------+----------------+------------+----------+-----------------+---------------------+--------------+-----------+-----------+-----------------------+------------------+---------------+--------------------+-------------+------------+-------------+-------------+--------------+-----------------+---------------------+--------------+-------------+------------------+------------------------+---------------------------+---------------+---------------+---------+-----------------------+------------------+------------+--------------+-------------+---------+----------+---------+--------------+----+\n",
      "|               150| 30|       354481|      2004-11-17|          IN|   100/300|             1000|              1342.02|             0|     608425|       MALE|                     MD|    prof-specialty|           polo|           own-child|            0|           0|   2015-02-28|   Parked Car|             ?|   Trivial Damage|                 None|            VA|    Arlington|      6317 Best St|                       8|                          1|            YES|              0|        2|                     NO|              4500|         450|           450|         3600|     Saab|        93|     1999|             N|null|\n",
      "|               125| 31|       205134|      2012-12-02|          IN|  500/1000|              500|              1220.86|             0|     436784|       MALE|                     JD|     other-service|      paintball|             husband|        55400|      -40400|   2015-01-24|   Parked Car|             ?|   Trivial Damage|                 None|            NY|    Arlington|9639 Britain Ridge|                       4|                          1|            YES|              1|        2|                      ?|              4320|           0|           960|         3360|     Saab|        93|     2003|             N|null|\n",
      "|               380| 53|       369781|      2011-05-25|          IL|   250/500|             2000|              1166.62|       6000000|     602500|       MALE|              Associate|   priv-house-serv| bungie-jumping|                wife|            0|           0|   2015-02-24|   Parked Car|             ?|   Trivial Damage|               Police|            NC|    Northbend|    8991 Texas Hwy|                      23|                          1|             NO|              0|        3|                     NO|              5700|         570|           570|         4560|     Saab|        93|     2001|             N|null|\n",
      "|               295| 48|       740019|      2009-06-17|          OH|   250/500|             1000|              1148.73|             0|     439787|     FEMALE|                College| machine-op-inspct|       kayaking|                wife|            0|           0|   2015-02-22|   Parked Car|             ?|   Trivial Damage|                 None|            WV|     Columbus|     3998 Flute St|                       6|                          1|              ?|              1|        2|                    YES|              5400|         900|           900|         3600|     Saab|        95|     1999|             N|null|\n",
      "|               271| 40|       873114|      1995-12-07|          IL|   100/300|             1000|              1251.65|             0|     433683|     FEMALE|              Associate|     other-service|        camping|                wife|        71200|           0|   2015-02-19|   Parked Car|             ?|     Minor Damage|                 None|            NY|    Hillsdale|  1365 Francis Ave|                       6|                          1|             NO|              0|        0|                     NO|              3080|         560|           280|         2240|     Audi|        A3|     2012|             N|null|\n",
      "+------------------+---+-------------+----------------+------------+----------+-----------------+---------------------+--------------+-----------+-----------+-----------------------+------------------+---------------+--------------------+-------------+------------+-------------+-------------+--------------+-----------------+---------------------+--------------+-------------+------------------+------------------------+---------------------------+---------------+---------------+---------+-----------------------+------------------+------------+--------------+-------------+---------+----------+---------+--------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words = spark.read.format(\"bigquery\") \\\n",
    "  .option(\"parentProject\", \"methodical-aura-373904\") \\\n",
    "  .option(\"dataset\", \"comp653\") \\\n",
    "  .option(\"table\", \"raw_insurance_claims\") \\\n",
    "  .load()\n",
    "\n",
    "words.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a597556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bac76e",
   "metadata": {},
   "source": [
    "## Local\n",
    "\n",
    "Uses the spark cluster stood up via docker-compose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4624cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://blog.det.life/pyspark-or-polars-what-should-you-use-breakdown-of-similarities-and-differences-b261a825b9d6\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Test\").config(\"spark.master\", f\"spark://{scheduler_ip}:7077\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fc7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [Row(id=1, age=25, salary=50000),\n",
    "         Row(id=2, age=30, salary=55000),\n",
    "         Row(id=3, age=35, salary=60000),\n",
    "         Row(id=4, age=40, salary=65000)]\n",
    "data2 = [Row(id=1, city=\"New York\"),\n",
    "         Row(id=2, city=\"San Francisco\"),\n",
    "         Row(id=3, city=\"Los Angeles\"),\n",
    "         Row(id=4, city=\"Chicago\")]\n",
    "\n",
    "df1_pyspark = spark.createDataFrame(data1)\n",
    "df2_pyspark = spark.createDataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca6d2b1-29b5-4602-bb17-1a1a1a62499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------------+-----------+\n",
      "| id|income|         city|high_income|\n",
      "+---+------+-------------+-----------+\n",
      "|  2| 55000|San Francisco|          0|\n",
      "|  3| 60000|  Los Angeles|          0|\n",
      "|  4| 65000|      Chicago|          1|\n",
      "+---+------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform operations\n",
    "selected_df = df1_pyspark.select(\"id\", \"salary\")\n",
    "filtered_df = selected_df.filter(col(\"salary\") > 50000)\n",
    "renamed_df = filtered_df.withColumnRenamed(\"salary\", \"income\")\n",
    "joined_df = renamed_df.join(df2_pyspark, on=\"id\", how=\"inner\")\n",
    "conditional_df = joined_df.withColumn(\"high_income\", when(col(\"income\") > 60000, 1).otherwise(0))\n",
    "conditional_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26e184bb-fac2-4f16-83f1-40470de8baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------------------------+\n",
      "|         city|average_income|average_increased_income|\n",
      "+-------------+--------------+------------------------+\n",
      "|      Chicago|       65000.0|                 70000.0|\n",
      "|  Los Angeles|       60000.0|                 65000.0|\n",
      "|San Francisco|       55000.0|                 60000.0|\n",
      "+-------------+--------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def salary_increase(salary: int) -> int:\n",
    "    return salary + 5000\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "salary_increase_udf = udf(salary_increase, IntegerType())\n",
    "udf_applied_df = conditional_df.withColumn(\n",
    "    \"increased_income\", salary_increase_udf(col(\"income\"))\n",
    ")\n",
    "\n",
    "window_spec = Window.orderBy(\"id\")\n",
    "ranked_df = udf_applied_df.withColumn(\"rank\", row_number().over(window_spec))\n",
    "\n",
    "# GroupBy and aggregation\n",
    "result_df = (\n",
    "    ranked_df.groupBy(\"city\")\n",
    "    .agg(\n",
    "        avg(\"income\").alias(\"average_income\"),\n",
    "        avg(\"increased_income\").alias(\"average_increased_income\"),\n",
    "    )\n",
    "    .sort(\"average_income\", ascending=False)\n",
    ")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "result_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9162fd67-7f8f-498a-946e-281300f33864",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stop the Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
